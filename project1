import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers,models,callbacks,callbacks
# Load MNIST dataset
(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()

# Convert to NumPy arrays
X_train_full, X_test = np.array(X_train_full), np.array(X_test)
y_train_full, y_test = np.array(y_train_full), np.array(y_test)

# Calculate sizes correctly (handling potential float results)
total_samples = len(X_train_full)
train_size = int(0.7 * total_samples)  # Convert 5/7 to an exact fraction for clarity
val_size = total_samples - train_size  # Ensure all samples are accounted for

# Split the data
X_train = X_train_full[:train_size]
y_train = y_train_full[:train_size]
X_val = X_train_full[train_size:train_size+val_size]  # Use all remaining samples for validation
y_val = y_train_full[train_size:train_size+val_size]
from tensorflow import keras
from tensorflow.keras.callbacks import EarlyStopping
X_train, X_val = X_train / 255.0, X_val / 255.0


# Define the model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(50, activation="relu"),
    keras.layers.Dense(50, activation="relu"),
    keras.layers.Dense(50, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

# Compile the model
model.compile(loss="sparse_categorical_crossentropy",
              optimizer="adam",
              metrics=["accuracy"])

# Print a summary of the model
model.summary()

# Count trainable parameters
total_params = model.count_params()
print("Total Trainable Parameters:", total_params)

# EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Model training
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])

#6) Plot the history of the loss and accuracy of the training process for the training and the validation set.
plt.figure(figsize=(12,6))

# Plot training & validation accuracy values
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.legend(['train', 'validation'], loc='upper right')
plt.show()

# Plot training & validation loss values
plt.subplot
plt.subplot(1,2,1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train' , 'validation'] , loc='upper right')
plt.show()

#What is the accuracy of your model on the test set?
test_loss , test_accuracy =model.evaluate(X_test , y_test)
